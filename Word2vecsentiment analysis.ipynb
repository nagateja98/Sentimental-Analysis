{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Word2vec_Naga.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "346c21bc94d945718d07473f51a8f91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bea32da8db1f447287c576099e78f574",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5a1223c7a7d47f3bc959524c525291b",
              "IPY_MODEL_462bc671943e407a8d6c01f9a1ddd3ff"
            ]
          }
        },
        "bea32da8db1f447287c576099e78f574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5a1223c7a7d47f3bc959524c525291b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1710ff0636f24f98b922563103fbf05c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 156060,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 156060,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c5e35f312934aa6b110e1f33276b385"
          }
        },
        "462bc671943e407a8d6c01f9a1ddd3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba3aa19ea34f48ca8d33264cc286f766",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 156060/156060 [00:28&lt;00:00, 5520.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_678a1dad1cd64789905db0bd48c696ea"
          }
        },
        "1710ff0636f24f98b922563103fbf05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c5e35f312934aa6b110e1f33276b385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba3aa19ea34f48ca8d33264cc286f766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "678a1dad1cd64789905db0bd48c696ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e95U9YmG_B7o",
        "colab_type": "code",
        "outputId": "13193c7c-1cbb-4e2f-dcb7-95415b1d5287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvmr6qee_CwL",
        "colab_type": "code",
        "outputId": "ade442a9-5434-4d4a-f94e-5d1e0f631e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Sentiment_Analysis_Rotten_Tomatoes/"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Sentiment_Analysis_Rotten_Tomatoes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWexRDozDo-Q",
        "outputId": "3d231afa-d909-4561-e652-412ac80dbd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python3 -m pip install pyspellchecker"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:40:47.846500Z",
          "start_time": "2020-03-17T16:40:47.813456Z"
        },
        "colab_type": "code",
        "id": "oFwQVwB6Do-b",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string, re\n",
        "from unicodedata import category, name, normalize\n",
        "from nltk.corpus import stopwords\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:40:49.499480Z",
          "start_time": "2020-03-17T16:40:49.206894Z"
        },
        "colab_type": "code",
        "id": "4PsTBBesDo-g",
        "outputId": "21a70879-4002-4a16-a9a4-321b280371f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = pd.read_csv('train.tsv',sep='\\t')\n",
        "train.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:40:49.557596Z",
          "start_time": "2020-03-17T16:40:49.533455Z"
        },
        "colab_type": "code",
        "id": "5SdrAWxRDo-l",
        "outputId": "d80eda29-6fd3-47da-c197-842ab0b8a30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:40:50.266479Z",
          "start_time": "2020-03-17T16:40:50.254089Z"
        },
        "colab_type": "code",
        "id": "TsPujKQwDo-u",
        "outputId": "c65d8d70-95a2-47f0-f61b-140e93e5ce29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "train['Phrase'][:10].values"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
              "       'A series of escapades demonstrating the adage that what is good for the goose',\n",
              "       'A series', 'A', 'series',\n",
              "       'of escapades demonstrating the adage that what is good for the goose',\n",
              "       'of',\n",
              "       'escapades demonstrating the adage that what is good for the goose',\n",
              "       'escapades',\n",
              "       'demonstrating the adage that what is good for the goose'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:40:51.731284Z",
          "start_time": "2020-03-17T16:40:51.273650Z"
        },
        "colab_type": "code",
        "id": "8QXmFIZ8Do-y",
        "outputId": "83dd4914-d055-4fd1-adab-4ab9fe6cc9af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "vc = train.Sentiment.value_counts()\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.barplot(vc.keys(), vc.values)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f696bcf7c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFlCAYAAAD/MAEVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKlzhrkkSZ0zzCVJ6tz/A4sOeXTkaG6dAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:40:52.949349Z",
          "start_time": "2020-03-17T16:40:52.851996Z"
        },
        "colab_type": "code",
        "id": "atjxf0Y5Do_D",
        "colab": {}
      },
      "source": [
        "# remove space\n",
        "def remove_space(text):\n",
        "    spaces = ['\\u200b', '\\u200e', '\\u202a', '\\u202c', '\\ufeff', '\\uf0d8', '\\u2061', '\\x10', '\\x7f', '\\x9d', '\\xad', '\\xa0']\n",
        "    for space in spaces:\n",
        "        text = text.replace(space, ' ')\n",
        "    text = text.strip()\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "#critics\n",
        "def remove_diacritics(s):\n",
        "    return ''.join(c for c in normalize('NFKD', s.replace('ø', 'o').replace('Ø', 'O').replace('⁻', '-').replace('₋', '-'))\n",
        "                  if category(c) != 'Mn')\n",
        "\n",
        "#clearn punctuations\n",
        "def clean_special_punctuations(text):\n",
        "    special_punc_mappings = {\"—\": \"-\", \"–\": \"-\", \"_\": \"-\", '”': '\"', \"″\": '\"', '“': '\"', '•': '.', '−': '-',\n",
        "                         \"’\": \"'\", \"‘\": \"'\", \"´\": \"'\", \"`\": \"'\", '\\u200b': ' ', '\\xa0': ' ','،':'','„':'',\n",
        "                         '…': ' ... ', '\\ufeff': ''}\n",
        "    for punc in special_punc_mappings:\n",
        "        if punc in text:\n",
        "            text = text.replace(punc, special_punc_mappings[punc])\n",
        "    text = remove_diacritics(text)\n",
        "    return text\n",
        "\n",
        "# clean numbers\n",
        "def clean_number(text):\n",
        "    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text) # digits followed by a single alphabet...\n",
        "    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text) #1st, 2nd, 3rd, 4th...\n",
        "    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n",
        "    return text\n",
        "\n",
        "# emojis\n",
        "def handle_emojis(text):\n",
        "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
        "    text = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', text)\n",
        "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
        "    text = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', text)\n",
        "    # Love -- <3, :*\n",
        "    text = re.sub(r'(<3|:\\*)', ' EMO_POS ', text)\n",
        "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
        "    text = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', text)\n",
        "    # Sad -- :-(, : (, :(, ):, )-:\n",
        "    text = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', text)\n",
        "    # Cry -- :,(, :'(, :\"(\n",
        "    text = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', text)\n",
        "    return text\n",
        "\n",
        "#stop words\n",
        "def stop(text):\n",
        "    text = \" \".join([w.lower() for w in text.split()])\n",
        "    stop_words = stopwords.words('english')\n",
        "    \n",
        "    words = [w for w in text.split() if not w in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# clean repeated letters\n",
        "def clean_repeat_words(text):\n",
        "    text = re.sub(r\"(I|i)(I|i)+ng\", \"ing\", text)\n",
        "    text = re.sub(r\"(L|l)(L|l)(L|l)+y\", \"lly\", text)\n",
        "    text = re.sub(r\"(A|a)(A|a)(A|a)+\", \"a\", text)\n",
        "    text = re.sub(r\"(C|c)(C|c)(C|c)+\", \"cc\", text)\n",
        "    text = re.sub(r\"(D|d)(D|d)(D|d)+\", \"dd\", text)\n",
        "    text = re.sub(r\"(E|e)(E|e)(E|e)+\", \"ee\", text)\n",
        "    text = re.sub(r\"(F|f)(F|f)(F|f)+\", \"ff\", text)\n",
        "    text = re.sub(r\"(G|g)(G|g)(G|g)+\", \"gg\", text)\n",
        "    text = re.sub(r\"(I|i)(I|i)(I|i)+\", \"i\", text)\n",
        "    text = re.sub(r\"(K|k)(K|k)(K|k)+\", \"k\", text)\n",
        "    text = re.sub(r\"(L|l)(L|l)(L|l)+\", \"ll\", text)\n",
        "    text = re.sub(r\"(M|m)(M|m)(M|m)+\", \"mm\", text)\n",
        "    text = re.sub(r\"(N|n)(N|n)(N|n)+\", \"nn\", text)\n",
        "    text = re.sub(r\"(O|o)(O|o)(O|o)+\", \"oo\", text)\n",
        "    text = re.sub(r\"(P|p)(P|p)(P|p)+\", \"pp\", text)\n",
        "    text = re.sub(r\"(Q|q)(Q|q)+\", \"q\", text)\n",
        "    text = re.sub(r\"(R|r)(R|r)(R|r)+\", \"rr\", text)\n",
        "    text = re.sub(r\"(S|s)(S|s)(S|s)+\", \"ss\", text)\n",
        "    text = re.sub(r\"(T|t)(T|t)(T|t)+\", \"tt\", text)\n",
        "    text = re.sub(r\"(V|v)(V|v)+\", \"v\", text)\n",
        "    text = re.sub(r\"(Y|y)(Y|y)(Y|y)+\", \"y\", text)\n",
        "    text = re.sub(r\"plzz+\", \"please\", text)\n",
        "    text = re.sub(r\"(Z|z)(Z|z)(Z|z)+\", \"zz\", text)\n",
        "    text = re.sub(r\"(-+|\\.+)\", \" \", text) #new haha #this adds a space token so we need to remove xtra spaces\n",
        "    return text\n",
        "\n",
        "# handle punctuation\n",
        "def spacing_punctuation(text):\n",
        "    regular_punct = list(string.punctuation)\n",
        "    extra_punct = [',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
        "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
        "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
        "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
        "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤',\n",
        "        ':)', ': )', ':-)', '(:', '( :', '(-:', ':\\')', ':D', ': D', ':-D', 'xD', 'x-D', 'XD', 'X-D',\n",
        "        '<3', ':*', ';-)', ';)', ';-D', ';D', '(;',  '(-;', ':-(', ': (', ':(', '\\'):', ')-:', '-- :','(', ':\\'(', ':\"(\\'']\n",
        "\n",
        "    all_punct = list(set(regular_punct + extra_punct))\n",
        "    all_punct.remove('-')\n",
        "    all_punct.remove('.')\n",
        "\n",
        "    for punc in all_punct:\n",
        "        if punc in text:\n",
        "            text = text.replace(punc, f' {punc} ')\n",
        "    return text\n",
        "    \n",
        "\n",
        "    \n",
        "#contraction map\n",
        "\n",
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
        "\n",
        "\n",
        "\n",
        "def correct_contraction(x, dic):\n",
        "    for word in dic.keys():\n",
        "        x = x.replace(word, dic[word])\n",
        "    return x\n",
        "\n",
        "# start pre-processing\n",
        "def preprocess(text):\n",
        "    text = remove_space(text)\n",
        "    text = correct_contraction(text, contraction_mapping)\n",
        "    text = clean_special_punctuations(text)\n",
        "    text = handle_emojis(text)\n",
        "    text = clean_number(text)\n",
        "    text = spacing_punctuation(text)\n",
        "    text = clean_repeat_words(text)\n",
        "    text = remove_space(text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:41:38.554356Z",
          "start_time": "2020-03-17T16:41:38.307102Z"
        },
        "colab_type": "code",
        "id": "rieX3srODo_N",
        "colab": {}
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)\n",
        "\n",
        "# text = \"speling correctin\"\n",
        "# correct_spellings(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-17T16:41:41.573447Z",
          "start_time": "2020-03-17T16:41:41.565331Z"
        },
        "colab_type": "code",
        "id": "ZlW5qNqLDo_W",
        "colab": {}
      },
      "source": [
        "def text_clean_wrapper(df):\n",
        "    df['Phrase'] = df['Phrase'].str.lower()\n",
        "    df[\"Phrase\"] = df[\"Phrase\"].astype('str').transform(preprocess)\n",
        "    # df['Phrase'] = df['Phrase'].transform(lambda x: correct_spellings(x))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-03-17T16:41:45.148Z"
        },
        "colab_type": "code",
        "id": "u30X83G2Do_g",
        "outputId": "dd4beb2e-aadf-47c9-bd03-3e54a5eb9325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import psutil, time\n",
        "from multiprocessing import Pool\n",
        "import multiprocessing\n",
        "num_cores = psutil.cpu_count()  \n",
        "num_partitions = 10  # number of partitions to split dataframe\n",
        "\n",
        "def run_thread(df, func):\n",
        "    df_split = np.array_split(df, num_partitions)\n",
        "    pool = Pool(num_cores)\n",
        "    df = pd.concat(pool.map(func, df_split))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return df\n",
        "\n",
        "start_time = time.time()\n",
        "print('Processing Started...')\n",
        "# preprocessing - multi thread run\n",
        "full_df = run_thread(train, text_clean_wrapper)\n",
        "print(full_df.shape)\n",
        "print(\"Pre-Process Run Time :: %s mins\" % ((time.time() - start_time)/60))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Started...\n",
            "(156060, 4)\n",
            "Pre-Process Run Time :: 0.282333509127299 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-03-17T16:42:38.349Z"
        },
        "colab_type": "code",
        "id": "N0mon7ljDo_l",
        "outputId": "222c5712-af7e-4f20-ec51-d89aaae6b024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "full_df.head(10)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>a series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUXa6nhxR9c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "# # Transform each text into a vector of word counts\n",
        "# # vectorizer = CountVectorizer(stop_words=\"english\",\n",
        "# # ngram_range=(1, 1))\n",
        "# vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
        "# ngram_range=(1, 1))\n",
        "# X = vectorizer.fit_transform(full_df[\"Phrase\"])\n",
        "# Y = all_data['Sentiment']\n",
        "# x_train = vectorizer.transform(train_data[\"text\"])\n",
        "# y_train = train_data['sentiment']\n",
        "# x_test = vectorizer.transform(test_data[\"text\"])\n",
        "# y_test = test_data['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ohjdDXR8-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uIqtAplqWvNm"
      },
      "source": [
        "### word2vec_cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rG9sDWE0WtoW",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load Google's pre-trained Word2Vec model.\n",
        "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fYT3TUXqfSOD",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 15000 # unique words = 15277  # total words 156060"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qaq6EBX2piKf",
        "colab_type": "code",
        "outputId": "751ee260-fa00-4e3b-d23a-798d93cf6aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "346c21bc94d945718d07473f51a8f91d",
            "bea32da8db1f447287c576099e78f574",
            "c5a1223c7a7d47f3bc959524c525291b",
            "462bc671943e407a8d6c01f9a1ddd3ff",
            "1710ff0636f24f98b922563103fbf05c",
            "6c5e35f312934aa6b110e1f33276b385",
            "ba3aa19ea34f48ca8d33264cc286f766",
            "678a1dad1cd64789905db0bd48c696ea"
          ]
        }
      },
      "source": [
        "list_of_sent=[]\n",
        "for sentence in tqdm(full_df['Phrase']):\n",
        "    fil_sent=[]\n",
        "    for word in sentence.split():\n",
        "        if (word.isalpha()):\n",
        "            fil_sent.append(word)\n",
        "        else:\n",
        "            continue\n",
        "    list_of_sent.append(fil_sent)\n",
        "\n",
        "\n",
        "w2v_model = gensim.models.Word2Vec(list_of_sent,min_count=5,size=100, workers = 4, sg = 1) #sg = 1(skip_gram),0(c_bow)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "346c21bc94d945718d07473f51a8f91d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=156060), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f7REtPsE5Ss_",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "Y = ohe.fit_transform(full_df['Sentiment'].values.reshape(-1,1))\n",
        "X_train, X_test, y_train, y_test = train_test_split(full_df['Phrase'], Y, test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dx3b9AZfdhnF",
        "outputId": "48fa5c66-4df4-4b54-b233-ab175419658e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "EMBEDDING_DIM =100\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(full_df['Phrase'].tolist())\n",
        "training_sequences = tokenizer.texts_to_sequences(X_train.tolist())\n",
        "\n",
        "train_word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(train_word_index))\n",
        "\n",
        "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
        "for word,index in train_word_index.items():\n",
        "    train_embedding_weights[index,:] = w2v_model[word] if word in w2v_model else np.random.rand(EMBEDDING_DIM)\n",
        "print(train_embedding_weights.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15262 unique tokens.\n",
            "(15263, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "250Zb3Sw6Ec3",
        "colab": {}
      },
      "source": [
        "train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test.tolist())\n",
        "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "18u9a41hCmv4",
        "outputId": "751b589e-16fc-48dc-ace5-17bf646ae9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import pickle\n",
        "import nltk\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense,Input,Flatten,Reshape,Dropout,Concatenate,Conv2D,MaxPool2D,Embedding,SpatialDropout1D,LSTM,LeakyReLU,PReLU,ThresholdedReLU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import SGD, Nadam, Adadelta,Adam,Adamax,Adagrad\n",
        "from keras.callbacks import ReduceLROnPlateau ,ModelCheckpoint, EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "!pip3 install keras-rectified-adam\n",
        "from keras_radam import RAdam"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Requirement already satisfied: keras-rectified-adam in /usr/local/lib/python3.6/dist-packages (0.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (1.18.2)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pWe-7M0MBRG8",
        "outputId": "ece231d6-491d-4b45-95fc-899fee77d3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filter_sizes = [1,2,3,5]#[1,2,3,5]\n",
        "num_filters = 256 #224 best\n",
        "drop = 0.5\n",
        "\n",
        "#     print(\"Creating Model...\")\n",
        "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedding = Embedding(input_dim=len(train_word_index) + 1, output_dim=EMBEDDING_DIM, weights=[train_embedding_weights],\n",
        "                      input_length=MAX_SEQUENCE_LENGTH, trainable=False)(inputs)\n",
        "reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
        "\n",
        "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "\n",
        "maxpool_0 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
        "maxpool_1 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
        "maxpool_2 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
        "\n",
        "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
        "flatten = Flatten()(concatenated_tensor)\n",
        "dropout = Dropout(drop)(flatten)\n",
        "preds = Dense(5, activation='softmax')(dropout)\n",
        "\n",
        "# this creates a model that includes inputs and outputs\n",
        "model = Model(inputs=inputs, outputs=preds) \n",
        "\n",
        "opt = Adam(lr=0.05)\n",
        "\n",
        "# opt = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=1e-5)\n",
        "\n",
        "# opt = keras.optimizers.Adadelta(lr=0.1, rho=0.95, epsilon=None, decay=0.0) # 1.65,0.969\n",
        "# opt = keras.optimizers.SGD(lr=0.5, momentum=0.0, decay=0.0, nesterov=False)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc']) #RAdam(),'adam'\n",
        "\n",
        "ckpt=ModelCheckpoint('/content/1104370_1dconv_reg.h5',monitor='val_acc',verbose=1,save_best_only=True)\n",
        "history = model.fit(train_cnn_data, y_train,   batch_size=512, epochs=30, validation_data=(test_cnn_data, y_test),callbacks=[ckpt])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/30\n",
            "109242/109242 [==============================] - 14s 128us/step - loss: 1.1862 - acc: 0.5356 - val_loss: 1.0635 - val_acc: 0.5777\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57771, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 2/30\n",
            "109242/109242 [==============================] - 13s 123us/step - loss: 1.0674 - acc: 0.5746 - val_loss: 1.0275 - val_acc: 0.5918\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57771 to 0.59182, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 3/30\n",
            "109242/109242 [==============================] - 13s 123us/step - loss: 1.0324 - acc: 0.5883 - val_loss: 1.0069 - val_acc: 0.5966\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.59182 to 0.59657, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 4/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 1.0071 - acc: 0.5987 - val_loss: 0.9913 - val_acc: 0.6049\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.59657 to 0.60494, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 5/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.9879 - acc: 0.6067 - val_loss: 0.9782 - val_acc: 0.6088\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.60494 to 0.60878, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 6/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.9675 - acc: 0.6159 - val_loss: 0.9665 - val_acc: 0.6124\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.60878 to 0.61241, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 7/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.9544 - acc: 0.6197 - val_loss: 0.9549 - val_acc: 0.6149\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.61241 to 0.61487, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 8/30\n",
            "109242/109242 [==============================] - 13s 123us/step - loss: 0.9407 - acc: 0.6260 - val_loss: 0.9433 - val_acc: 0.6261\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.61487 to 0.62606, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 9/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.9296 - acc: 0.6302 - val_loss: 0.9577 - val_acc: 0.6198\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.62606\n",
            "Epoch 10/30\n",
            "109242/109242 [==============================] - 13s 123us/step - loss: 0.9165 - acc: 0.6353 - val_loss: 0.9288 - val_acc: 0.6291\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.62606 to 0.62907, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 11/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.9074 - acc: 0.6394 - val_loss: 0.9247 - val_acc: 0.6318\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.62907 to 0.63179, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 12/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.9006 - acc: 0.6428 - val_loss: 0.9207 - val_acc: 0.6327\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.63179 to 0.63273, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 13/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8898 - acc: 0.6465 - val_loss: 0.9170 - val_acc: 0.6346\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.63273 to 0.63465, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 14/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8844 - acc: 0.6503 - val_loss: 0.9205 - val_acc: 0.6344\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.63465\n",
            "Epoch 15/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8775 - acc: 0.6521 - val_loss: 0.9094 - val_acc: 0.6386\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.63465 to 0.63864, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 16/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8699 - acc: 0.6549 - val_loss: 0.9101 - val_acc: 0.6382\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.63864\n",
            "Epoch 17/30\n",
            "109242/109242 [==============================] - 13s 123us/step - loss: 0.8694 - acc: 0.6561 - val_loss: 0.9040 - val_acc: 0.6414\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.63864 to 0.64136, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 18/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8625 - acc: 0.6587 - val_loss: 0.9018 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.64136\n",
            "Epoch 19/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8544 - acc: 0.6612 - val_loss: 0.9009 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.64136 to 0.64157, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 20/30\n",
            "109242/109242 [==============================] - 13s 123us/step - loss: 0.8509 - acc: 0.6635 - val_loss: 0.8992 - val_acc: 0.6433\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.64157 to 0.64326, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 21/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8456 - acc: 0.6648 - val_loss: 0.8986 - val_acc: 0.6433\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.64326 to 0.64328, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 22/30\n",
            "109242/109242 [==============================] - 13s 121us/step - loss: 0.8418 - acc: 0.6649 - val_loss: 0.8967 - val_acc: 0.6447\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.64328 to 0.64469, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 23/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8373 - acc: 0.6686 - val_loss: 0.8946 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.64469\n",
            "Epoch 24/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8339 - acc: 0.6684 - val_loss: 0.8903 - val_acc: 0.6464\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.64469 to 0.64640, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 25/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8308 - acc: 0.6722 - val_loss: 0.8905 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.64640 to 0.64652, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 26/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8287 - acc: 0.6720 - val_loss: 0.8930 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.64652 to 0.64708, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 27/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8264 - acc: 0.6719 - val_loss: 0.8900 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.64708\n",
            "Epoch 28/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8221 - acc: 0.6748 - val_loss: 0.8904 - val_acc: 0.6465\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.64708\n",
            "Epoch 29/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8167 - acc: 0.6752 - val_loss: 0.8922 - val_acc: 0.6473\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.64708 to 0.64729, saving model to /content/1104370_1dconv_reg.h5\n",
            "Epoch 30/30\n",
            "109242/109242 [==============================] - 13s 122us/step - loss: 0.8166 - acc: 0.6760 - val_loss: 0.8875 - val_acc: 0.6489\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.64729 to 0.64885, saving model to /content/1104370_1dconv_reg.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e44QBdL6DBur",
        "outputId": "b200c940-fac0-4b3b-a7cb-619980d1b9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(train_cnn_data, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(test_cnn_data, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.7183\n",
            "Testing Accuracy:  0.6489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3rhE-QAeXEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#activation=elu\n",
        "#optimizer=adm, lr=0.05\n",
        "\n",
        "# Training Accuracy: 0.6915\n",
        "# Testing Accuracy:  0.6381\n",
        "\n",
        "#num_filters=256\n",
        "# Training Accuracy: 0.6968\n",
        "# Testing Accuracy:  0.6403"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWtvz73VTaUo",
        "colab": {}
      },
      "source": [
        "# prediction on validation data\n",
        "y_pred = model.predict(test_cnn_data)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aiCLdSX8TpvO",
        "colab": {}
      },
      "source": [
        "y_test1 = []\n",
        "for i in y_test:\n",
        "  y_test1.append(np.argmax(i))\n",
        "y_test1 = np.array(y_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vCAbl-p9io27",
        "outputId": "e67b5351-0d38-4217-a45d-349a3c6707af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test1, y_pred, target_names=['1','2','3','4','5']))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.24      0.34      2151\n",
            "           2       0.54      0.43      0.48      8070\n",
            "           3       0.69      0.87      0.77     23987\n",
            "           4       0.59      0.48      0.53      9872\n",
            "           5       0.60      0.30      0.40      2738\n",
            "\n",
            "    accuracy                           0.65     46818\n",
            "   macro avg       0.60      0.46      0.50     46818\n",
            "weighted avg       0.63      0.65      0.63     46818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fhldz6jzTWr7",
        "outputId": "fd02188d-8860-4bea-bcfb-afa97186806d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test1, y_pred, target_names=['1','2','3','4','5']))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.24      0.34      2151\n",
            "           2       0.54      0.43      0.48      8070\n",
            "           3       0.69      0.87      0.77     23987\n",
            "           4       0.59      0.48      0.53      9872\n",
            "           5       0.60      0.30      0.40      2738\n",
            "\n",
            "    accuracy                           0.65     46818\n",
            "   macro avg       0.60      0.46      0.50     46818\n",
            "weighted avg       0.63      0.65      0.63     46818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zTDS0NQhJ5UX",
        "outputId": "c088ed6a-5027-416f-f124-783335176dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
        "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
        "#on accuracy and learning curve.\n",
        "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
        "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjnnQvIA4ZxzLqT/D2+EkJEtE18xAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xl9Zkjd5kgd4",
        "outputId": "a589d2c0-0e23-46df-acc4-7dfa3e204e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "print(multiclass_roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.672143080837919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1RCFCT9HbEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"/content/1104370_1dconv_reg.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}